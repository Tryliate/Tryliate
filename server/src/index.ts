import express, { Request, Response, NextFunction } from 'express';
import cors from 'cors';
import { createClient } from '@supabase/supabase-js';
import pkg from 'pg';
const { Client } = pkg;
import crypto from 'crypto';
import dotenv from 'dotenv';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { db, pool } from './db/index';
import { nodes, edges, mcpRegistry, flowSpace, mcpAuthorizations, neuralDiscoveryQueue, foundryNodes, agentMemory, workspaceHistory } from './db/schema';
import { NeuralAI } from './ai';
import { GuardianEnforcer, NeuralScope } from './guardian';
import { trackExecution, redis } from './redis.ts';
import { eq, desc, and } from 'drizzle-orm';
import { z } from 'zod';
import { PostgresQueueAdapter } from './engine/native/adapters/postgres.ts';
import { NativeExecutor } from './engine/native/executor.ts';


// process.env.NODE_TLS_REJECT_UNAUTHORIZED = '0'; // Retired in favor of Official Supabase MCP Bridge

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

dotenv.config({ path: path.join(__dirname, '../../.env.local') });
dotenv.config(); // Fallback to default .env

console.log('--- STARTUP DEBUG ---');
console.log('SUPABASE_URL present:', !!process.env.SUPABASE_URL);
console.log('SUPABASE_SECRET_KEY present:', !!process.env.SUPABASE_SECRET_KEY);
console.log('--- END STARTUP DEBUG ---');

// Unified Infrastructure Config
const SUPABASE_URL = (process.env.SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL || '').trim();
const SUPABASE_SECRET_KEY = (process.env.SUPABASE_SECRET_KEY || '').trim();

console.log(`DEBUG: SUPABASE_URL length: ${SUPABASE_URL.length}`);
if (SUPABASE_URL) {
  console.log(`DEBUG: SUPABASE_URL starts with: ${SUPABASE_URL.substring(0, 10)}`);
}

const app = express();
app.use(cors());
app.use(express.json());

const PORT = parseInt(process.env.PORT || '8080');

app.use((req: Request, res: Response, next: NextFunction) => {
  console.log(`[${new Date().toISOString()}] ${req.method} ${req.url}`);
  next();
});

// --- REQUEST SCHEMAS ---
const ProvisionSchema = z.object({
  accessToken: z.string().optional(),
  userId: z.string().uuid()
});

const SyncSchema = z.object({
  projectId: z.string().min(5),
  accessToken: z.string().min(10),
  dbPass: z.string().min(8)
});



const ResetSchema = z.object({
  userId: z.string().uuid()
});

const SyncDatabaseSchema = z.object({
  userId: z.string().uuid()
});

const IngestSchema = z.object({
  type: z.string().optional()
});

const ProxySchema = z.object({
  type: z.string().optional()
}).catchall(z.any());

const DiscoverySchema = z.object({
  url: z.string().url(),
  name: z.string().optional(),
  detectedBy: z.string()
});

const AuthorizeSchema = z.object({
  userId: z.string().uuid(),
  provider: z.string(),
  scopes: z.array(z.string())
});

const RecallSchema = z.object({
  agentId: z.string(),
  query: z.string(),
  limit: z.number().optional().default(5)
});

const SaveMemorySchema = z.object({
  agentId: z.string(),
  userId: z.string().uuid(),
  content: z.string().min(1),
  memoryType: z.string().optional().default('short_term'),
  metadata: z.any().optional()
});

const ToolCallSchema = z.object({
  userId: z.string().uuid(),
  provider: z.string(),
  tool: z.string(),
  arguments: z.any()
});

app.get('/', (req: Request, res: Response) => {
  res.json({
    status: 'online',
    engine: 'Tryliate Neural Engine v1.1.1',
    runtime: 'Bun'
  });
});



app.get('/health', async (req: Request, res: Response) => {
  const health: any = {
    status: 'OK',
    timestamp: new Date().toISOString(),
    services: {
      supabase: 'probing',
      neon: 'probing',
      redis: 'probing'
    }
  };

  try {
    // 1. Check Supabase
    const supabase = createClient(SUPABASE_URL, SUPABASE_SECRET_KEY);
    const { error: sbError } = await supabase.from('users').select('count', { count: 'exact', head: true });
    health.services.supabase = sbError ? `error: ${sbError.message}` : 'healthy';

    // 2. Check Neon (Drizzle)
    try {
      await pool.query('SELECT 1');
      health.services.neon = 'healthy';
    } catch (e: any) {
      health.services.neon = `error: ${e.message}`;
    }

    // 3. Check Redis (Upstash)
    try {
      await redis.ping();
      health.services.redis = 'healthy';
    } catch (e: any) {
      health.services.redis = `error: ${e.message}`;
    }

    const isAllHealthy = Object.values(health.services).every(v => v === 'healthy');
    res.status(isAllHealthy ? 200 : 207).json(health);
  } catch (err: any) {
    res.status(500).json({ status: 'ERROR', message: err.message, services: health.services });
  }
});

app.get('/api/debug/schema-init', async (req: Request, res: Response) => {
  try {
    console.log('üõ†Ô∏è DEBUG: Initializing Schema via Pool...');
    await pool.query(BYOI_SCHEMA_SQL);
    res.json({ success: true, message: 'Schema initialized successfully.' });
  } catch (err: any) {
    console.error('‚ùå Schema Init Failed:', err);
    res.status(500).json({ error: err.message });
  }
});

const BYOI_SCHEMA_SQL = `
-- üî± Neural Core Extension Support
CREATE EXTENSION IF NOT EXISTS vector;

-- BYOI Core Neural Infrastructure
CREATE TABLE IF NOT EXISTS public.workflows (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name TEXT NOT NULL DEFAULT 'Untitled Workflow',
  description TEXT,
  state JSONB DEFAULT '{"viewport": {"x": 0, "y": 0, "zoom": 1}}',
  created_at TIMESTAMPTZ DEFAULT now(),
  updated_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.nodes (
  id TEXT PRIMARY KEY,
  workflow_id UUID REFERENCES public.workflows(id) ON DELETE CASCADE,
  type TEXT NOT NULL,
  data JSONB NOT NULL,
  position_x FLOAT NOT NULL,
  position_y FLOAT NOT NULL,
  width FLOAT,
  height FLOAT,
  created_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.edges (
  id TEXT PRIMARY KEY,
  workflow_id UUID REFERENCES public.workflows(id) ON DELETE CASCADE,
  source TEXT NOT NULL,
  target TEXT NOT NULL,
  source_handle TEXT,
  target_handle TEXT,
  data JSONB,
  created_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.mcp_registry (
  id TEXT PRIMARY KEY,
  name TEXT NOT NULL,
  url TEXT,
  type TEXT DEFAULT 'server',
  data JSONB,
  updated_at TIMESTAMPTZ DEFAULT now()
);


CREATE TABLE IF NOT EXISTS public.mcp_authorizations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID,
  provider TEXT NOT NULL,
  access_token TEXT NOT NULL,
  refresh_token TEXT,
  scopes JSONB DEFAULT '[]', -- Neural Guardian: Granular permissions
  metadata JSONB DEFAULT '{}',
  expires_at TIMESTAMPTZ,
  status TEXT DEFAULT 'verified',
  last_handshake_at TIMESTAMPTZ DEFAULT now(),
  created_at TIMESTAMPTZ DEFAULT now(),
  updated_at TIMESTAMPTZ DEFAULT now(),
  UNIQUE(user_id, provider)
);

CREATE TABLE IF NOT EXISTS public.flow_space (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID,
  name TEXT NOT NULL DEFAULT 'Untitled Flow',
  messages JSONB DEFAULT '[]',
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT now(),
  updated_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.workspace_history (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID,
  action TEXT NOT NULL,
  details JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.foundry_nodes (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  label TEXT NOT NULL,
  type TEXT NOT NULL,
  category TEXT NOT NULL,
  sub_category TEXT,
  data JSONB NOT NULL,
  created_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.agent_memory (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  agent_id TEXT NOT NULL,
  user_id UUID,
  memory_type TEXT DEFAULT 'short_term',
  content TEXT,
  embedding vector(1536), -- Neural Memory: Semantic search support
  metadata JSONB,
  created_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.neural_discovery_queue (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_url TEXT NOT NULL,
  mcp_name TEXT,
  status TEXT DEFAULT 'pending', -- pending, installing, complete, failed
  detected_by TEXT, -- Agent ID or Discovery Engine
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT now(),
  updated_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.neural_links (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_node_id TEXT,
  target_node_id TEXT,
  correlation_score FLOAT,
  metadata JSONB,
  created_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.tool_catalog (
  id TEXT PRIMARY KEY,
  mcp_server_id TEXT,
  name TEXT NOT NULL,
  description TEXT,
  input_schema JSONB,
  is_verified BOOLEAN DEFAULT false,
  created_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.audit_trail (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID,
  action TEXT NOT NULL,
  entity_type TEXT,
  entity_id TEXT,
  details JSONB,
  ip_address TEXT,
  created_at TIMESTAMPTZ DEFAULT now()
);

CREATE TABLE IF NOT EXISTS public.user_settings (
  user_id UUID PRIMARY KEY,
  theme TEXT DEFAULT 'dark',
  notifications_enabled BOOLEAN DEFAULT true,
  ai_model_preference TEXT DEFAULT 'gpt-4',
  metadata JSONB DEFAULT '{}',
  updated_at TIMESTAMPTZ DEFAULT now()
);

-- Optimization Indices
CREATE INDEX IF NOT EXISTS idx_nodes_workflow_id ON public.nodes(workflow_id);
CREATE INDEX IF NOT EXISTS idx_edges_workflow_id ON public.edges(workflow_id);
CREATE INDEX IF NOT EXISTS idx_mcp_registry_updated_at ON public.mcp_registry(updated_at DESC);
CREATE INDEX IF NOT EXISTS idx_mcp_authorizations_user_id ON public.mcp_authorizations(user_id);
CREATE INDEX IF NOT EXISTS idx_flow_space_user_id ON public.flow_space(user_id);
CREATE INDEX IF NOT EXISTS idx_agent_memory_agent_id ON public.agent_memory(agent_id);
CREATE INDEX IF NOT EXISTS idx_agent_memory_embedding ON public.agent_memory USING hnsw (embedding vector_cosine_ops);
CREATE INDEX IF NOT EXISTS idx_neural_discovery_status ON public.neural_discovery_queue(status);
CREATE INDEX IF NOT EXISTS idx_neural_links_nodes ON public.neural_links(source_node_id, target_node_id);
CREATE INDEX IF NOT EXISTS idx_tool_catalog_server ON public.tool_catalog(mcp_server_id);

-- Access Control
ALTER TABLE public.workflows ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.nodes ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.edges ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.mcp_registry ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.mcp_authorizations ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.flow_space ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.workspace_history ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.foundry_nodes ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.agent_memory ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.neural_links ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.tool_catalog ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.audit_trail ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.user_settings ENABLE ROW LEVEL SECURITY;

-- Basic Policies (Allow all for now as it is BYOI)
DROP POLICY IF EXISTS "Enable all for users" ON public.workflows;
CREATE POLICY "Enable all for users" ON public.workflows FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.nodes;
CREATE POLICY "Enable all for users" ON public.nodes FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.edges;
CREATE POLICY "Enable all for users" ON public.edges FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.mcp_registry;
CREATE POLICY "Enable all for users" ON public.mcp_registry FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.mcp_authorizations;
CREATE POLICY "Enable all for users" ON public.mcp_authorizations FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.flow_space;
CREATE POLICY "Enable all for users" ON public.flow_space FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.workspace_history;
CREATE POLICY "Enable all for users" ON public.workspace_history FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.foundry_nodes;
CREATE POLICY "Enable all for users" ON public.foundry_nodes FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.agent_memory;
CREATE POLICY "Enable all for users" ON public.agent_memory FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.neural_links;
CREATE POLICY "Enable all for users" ON public.neural_links FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.tool_catalog;
CREATE POLICY "Enable all for users" ON public.tool_catalog FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.audit_trail;
CREATE POLICY "Enable all for users" ON public.audit_trail FOR ALL USING (true);
DROP POLICY IF EXISTS "Enable all for users" ON public.user_settings;
CREATE POLICY "Enable all for users" ON public.user_settings FOR ALL USING (true);

-- Realtime Neural Sync
DO $$
DECLARE
  t text;
BEGIN
  IF NOT EXISTS (SELECT 1 FROM pg_publication WHERE pubname = 'supabase_realtime') THEN
    CREATE PUBLICATION supabase_realtime;
  END IF;

  FOREACH t IN ARRAY ARRAY[
    'public.workflows', 'public.nodes', 'public.edges', 
    'public.mcp_registry', 'public.mcp_authorizations', 'public.flow_space', 
    'public.workspace_history', 'public.foundry_nodes', 'public.agent_memory', 
    'public.neural_links', 'public.tool_catalog'
  ] LOOP
    BEGIN
      EXECUTE format('ALTER PUBLICATION supabase_realtime ADD TABLE %s', t);
    EXCEPTION WHEN others THEN NULL;
    END;
  END LOOP;
END $$;
`;

const NATIVE_ENGINE_SQL = `
CREATE EXTENSION IF NOT EXISTS pg_cron;
CREATE SCHEMA IF NOT EXISTS tryliate;

CREATE TABLE IF NOT EXISTS tryliate.jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  run_id UUID NOT NULL,
  workflow_id TEXT NOT NULL,
  node_id TEXT NOT NULL,
  payload JSONB NOT NULL DEFAULT '{}',
  status TEXT NOT NULL DEFAULT 'pending', 
  attempts INT NOT NULL DEFAULT 0,
  max_attempts INT NOT NULL DEFAULT 3,
  next_run_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_jobs_status_run ON tryliate.jobs (status, next_run_at);

CREATE TABLE IF NOT EXISTS tryliate.runs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  workflow_id TEXT NOT NULL,
  user_id TEXT NOT NULL,
  status TEXT NOT NULL,
  input JSONB,
  output JSONB,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE TABLE IF NOT EXISTS tryliate.steps (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  run_id UUID NOT NULL,
  node_id TEXT NOT NULL,
  status TEXT NOT NULL,
  input JSONB,
  output JSONB,
  error TEXT,
  started_at TIMESTAMP WITH TIME ZONE,
  completed_at TIMESTAMP WITH TIME ZONE
);

-- Try to add to publication if it exists
DO $$
BEGIN
  IF EXISTS (SELECT 1 FROM pg_publication WHERE pubname = 'supabase_realtime') THEN
    ALTER PUBLICATION supabase_realtime ADD TABLE tryliate.jobs, tryliate.runs, tryliate.steps;
  END IF;
EXCEPTION WHEN others THEN NULL;
END $$;
`;





/**
 * Official Supabase MCP Bridge Caller (Stateful)
 * Executes JSON-RPC tools with session awareness
 */
async function initializeSupabaseMCP(projectId: string, accessToken: string): Promise<string> {
  const url = `https://mcp.supabase.com/mcp?project_ref=${projectId}`;
  const payload = {
    jsonrpc: '2.0',
    id: 0,
    method: 'initialize',
    params: {
      protocolVersion: '2024-11-05',
      capabilities: {},
      clientInfo: { name: 'Tryliate-Engine', version: '1.2.0' }
    }
  };

  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${accessToken}`,
      'Content-Type': 'application/json',
      'Accept': 'application/json, text/event-stream',
      'x-supabase-project': projectId
    },
    body: JSON.stringify(payload)
  });

  if (!response.ok) {
    const errText = await response.text();
    throw new Error(`MCP Handshake Failed (${response.status}): ${errText}`);
  }

  const sessionId = response.headers.get('mcp-session-id');
  return sessionId || "";
}

async function callSupabaseMCP(projectId: string, accessToken: string, tool: string, args: any, sessionId: string | null = null): Promise<any> {
  const url = `https://mcp.supabase.com/mcp?project_ref=${projectId}`;

  const payload = {
    jsonrpc: '2.0',
    id: Date.now(),
    method: 'tools/call',
    params: {
      name: tool,
      arguments: args
    }
  };

  const headers: Record<string, string> = {
    'Authorization': `Bearer ${accessToken}`,
    'Content-Type': 'application/json',
    'Accept': 'application/json, text/event-stream',
    'x-supabase-project': projectId
  };

  if (sessionId) headers['mcp-session-id'] = sessionId;

  try {
    const response = await fetch(url, {
      method: 'POST',
      headers: headers,
      body: JSON.stringify(payload)
    });

    if (!response.ok) {
      const errText = await response.text();
      console.error(`‚ùå MCP Bridge HTTP Error [${response.status}]: ${errText}`);
      throw new Error(`MCP Bridge Offline (${response.status}): ${errText}`);
    }

    const result: any = await response.json();
    if (result.error) {
      console.error(`‚ùå MCP JSON-RPC Error:`, JSON.stringify(result.error));
      throw new Error(result.error.message || 'Unknown MCP RPC Error');
    }

    // Check for internal tool errors (standard MCP return format)
    if (result.result && result.result.isError) {
      const toolErr = result.result.content?.[0]?.text || 'Tool execution failed';
      console.error(`‚ùå MCP Tool Execution Error:`, toolErr);
      throw new Error(toolErr);
    }

    return result.result;
  } catch (err: any) {
    if (err.name === 'AbortError') throw new Error('MCP Request Timeout');
    throw err;
  }
}

/**
 * Smarter SQL splitter that respects DO blocks and dollar-quoting ($$)
 */
function splitSqlStatements(sql: string): string[] {
  const statements: string[] = [];
  let current = '';
  let inDollarQuote = false;

  const lines = sql.split('\n');
  for (let line of lines) {
    // Basic check for dollar quoting $$, $tag$
    if (line.includes('$$')) {
      inDollarQuote = !inDollarQuote;
    }

    current += line + '\n';

    if (!inDollarQuote && line.trim().endsWith(';')) {
      statements.push(current.trim());
      current = '';
    }
  }

  if (current.trim()) statements.push(current.trim());
  return statements.filter(s => s.length > 0);
}

async function waitForProjectActive(projectId: string, accessToken: string): Promise<any> {
  // Tryliate Limit: 60 Seconds (12 attempts * 5000ms)
  for (let i = 0; i < 12; i++) {
    const res = await fetch(`https://api.supabase.com/v1/projects/${projectId}`, {
      headers: { 'Authorization': `Bearer ${accessToken}` }
    });

    if (res.ok) {
      const data: any = await res.json();
      if (data.status === 'ACTIVE_HEALTHY' || data.status === 'ACTIVE') return data;
    }
    await new Promise(r => setTimeout(r, 5000));
  }
  throw new Error('Project failed to become active in time.');
}


app.post('/api/infrastructure/provision', async (req: Request, res: Response, next: NextFunction) => {
  const sendStep = (message: string, type: 'info' | 'success' | 'error' = 'info') => {
    if (!res.writableEnded) res.write(JSON.stringify({ message, type }) + '\n');
  };

  try {
    let { accessToken, userId } = ProvisionSchema.parse(req.body);

    // Initialize Admin Supabase Client Early
    const supabase = createClient(SUPABASE_URL, SUPABASE_SECRET_KEY, {
      auth: { autoRefreshToken: false, persistSession: false }
    });

    if (!accessToken) {
      console.log(`[PROVISION] Token missing for ${userId}. Fetching from Vault...`);
      const { data: vaultData } = await supabase.from('users').select('supabase_access_token').eq('id', userId).single();
      accessToken = vaultData?.supabase_access_token;
    }

    if (!accessToken) {
      throw new Error('Supabase Authorization is missing or expired. Please re-connect.');
    }

    // Set up response
    res.setHeader('Content-Type', 'text/plain; charset=utf-8');
    res.setHeader('X-Content-Type-Options', 'nosniff');
    res.write(' '.repeat(1024) + '\n');

    const execCount = await trackExecution(userId);
    console.log(`[REDIS] Execution count for ${userId}: ${execCount}`);

    sendStep('ü§ñ Trymate: Analyzing infrastructure quotas...');

    let rawToken = accessToken;
    // 1. List Projects
    if (accessToken && !accessToken.startsWith('sbp_') && !accessToken.startsWith('sb_') && !accessToken.startsWith('eyJ')) {
      try {
        // Try to decode if it looks like base64 (doesn't start with standard Supabase prefixes)
        const decoded = Buffer.from(accessToken, 'base64').toString();
        if (decoded.startsWith('sbp_') || decoded.startsWith('sb_') || decoded.startsWith('eyJ')) {
          rawToken = decoded;
          console.log('üîì Decoded base64 access token.');
        }
      } catch (e) { }
    }

    const projectsResponse = await fetch('https://api.supabase.com/v1/projects', {
      headers: { 'Authorization': `Bearer ${rawToken}` }
    });

    if (!projectsResponse.ok) {
      const errorText = await projectsResponse.text();
      console.error('Supabase API Error:', projectsResponse.status, errorText);
      if (projectsResponse.status === 401) {
        throw new Error('Supabase Management session expired. Please re-authorize your account.');
      }
      throw new Error(`Failed to list projects: ${projectsResponse.status} ${errorText}`);
    }
    const projects: any[] = await projectsResponse.json() as any[];

    let targetProject = projects.find(p => p.name === 'Tryliate Studio');
    let dbPass: string | null = null;
    let _isNew = false;

    // Unified admin client session

    if (targetProject) {
      sendStep(`‚úÖ Found existing project entry: ${targetProject.id}`);

      // Stage 0: Save project ID immediately so it's not NULL in the DB anymore
      await supabase.from('users').update({
        supabase_project_id: targetProject.id,
        supabase_org_id: targetProject.organization_id || targetProject.organizationId || ''
      }).eq('id', userId);

      // Attempt to retrieve stored password from our vault
      const { data: userData } = await supabase
        .from('users')
        .select('supabase_db_pass, supabase_project_id')
        .eq('id', userId)
        .single();

      const storedProjectId = userData?.supabase_project_id === 'PENDING_SETUP' || userData?.supabase_project_id === 'UEVORElOR19TRVRVUA=='
        ? null
        : userData?.supabase_project_id;

      if (userData && storedProjectId === targetProject.id && userData.supabase_db_pass) {
        dbPass = userData.supabase_db_pass;
        sendStep('üîê Retrieved secured credentials from vault.');
      } else {
        // RECOVERY CASE: Project exists but we don't have the password.
        sendStep('‚ö†Ô∏è Orphaned project detected. Purging stale infrastructure...');
        try {
          const deleteRes = await fetch(`https://api.supabase.com/v1/projects/${targetProject.id}`, {
            method: 'DELETE',
            headers: { 'Authorization': `Bearer ${rawToken}` }
          });
          if (deleteRes.ok) {
            sendStep('‚ôªÔ∏è Removed stale infrastructure. Ready for fresh calibration.');
            targetProject = null; // Success, proceed to create
          } else {
            const errText = await deleteRes.text();
            sendStep(`‚ùå Critical: Could not purge existing project (${deleteRes.status}). Please delete "Tryliate Studio" manually in Supabase.`, 'error');
            throw new Error(`Orphaned project lockout: ${errText}`);
          }
        } catch (e: any) {
          sendStep(`‚ùå Recovery Bridge Failed: ${e.message}`, 'error');
          throw e;
        }
      }
    }

    if (!targetProject) {
      sendStep('üèóÔ∏è Trymate: Provisioning "Tryliate Studio" database...');
      const orgsResponse = await fetch('https://api.supabase.com/v1/organizations', {
        headers: { 'Authorization': `Bearer ${rawToken}` }
      });
      const organizations: any[] = await orgsResponse.json() as any[];
      const primaryOrg = organizations[0];

      if (!primaryOrg) throw new Error('No Supabase organization found for this account.');

      dbPass = crypto.randomBytes(16).toString('hex') + 'A1!';

      const createResponse = await fetch('https://api.supabase.com/v1/projects', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${rawToken}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          name: 'Tryliate Studio',
          organization_id: primaryOrg.id,
          region: 'us-east-1',
          plan: 'free',
          db_pass: dbPass
        })
      });
      if (!createResponse.ok) {
        const err = await createResponse.text();
        throw new Error(`Project creation failed: ${err}`);
      }
      targetProject = await createResponse.json();
      _isNew = true;
      sendStep(`‚ú® Created new project: ${targetProject.id}`);

      // Stage 0.1: Save new project ID
      await supabase.from('users').update({
        supabase_project_id: targetProject.id,
        supabase_org_id: targetProject.organization_id || targetProject.organizationId || primaryOrg.id
      }).eq('id', userId);
    }

    sendStep('üîë Fetching secure access keys...');
    const keysRes = await fetch(`https://api.supabase.com/v1/projects/${targetProject.id}/api-keys`, {
      headers: { 'Authorization': `Bearer ${rawToken}` }
    });

    if (!keysRes.ok) {
      const errText = await keysRes.text();
      throw new Error(`Failed to fetch API keys: ${errText}`);
    }

    const keys: any[] = await keysRes.json() as any[];
    const serviceRoleKey = (Array.isArray(keys) ? keys : []).find(k => k.name === 'service_role')?.api_key;
    const anonKey = (Array.isArray(keys) ? keys : []).find(k => k.name === 'anon')?.api_key;

    if (!serviceRoleKey) {
      console.error('DEBUG: API Keys Response:', JSON.stringify(keys));
      throw new Error('Service Role Key not found in project keys response.');
    }

    // ---------------------------------------------------------
    // STAGE 1: IMMEDIATE CREDENTIALS SAVE
    // ---------------------------------------------------------
    sendStep('üõ°Ô∏è Securing architectural keys in vault...');

    if (!serviceRoleKey) throw new Error('Cannot proceed: Service Role Key is missing.');
    if (!dbPass) throw new Error('Cannot proceed: Database Password is missing.');

    const stage1UpdateData = {
      supabase_connected: true,
      supabase_org_id: targetProject.organization_id || targetProject.organizationId || '',
      supabase_project_id: targetProject.id,
      supabase_service_role_key: serviceRoleKey,
      user_supabase_url: `https://${targetProject.id}.supabase.co`,
      user_supabase_anon_key: anonKey,
      supabase_db_pass: dbPass,
      supabase_access_token: accessToken,
      tryliate_initialized: false // Reset until Stage 3 is complete
    };

    console.log(`DEBUG: [Stage 1] Saving User Data: ${JSON.stringify({
      id: userId,
      project: stage1UpdateData.supabase_project_id,
      has_pass: !!stage1UpdateData.supabase_db_pass,
      has_key: !!stage1UpdateData.supabase_service_role_key
    })}`);

    const { error: stage1Error } = await supabase
      .from('users')
      .update(stage1UpdateData)
      .eq('id', userId);

    if (stage1Error) {
      console.error('PROVISIONING: Stage 1 Save Failed:', stage1Error);
      throw new Error(`Failed to secure credentials in Administrative Vault: ${stage1Error.message}. Check Service Role Key.`);
    }
    sendStep('üíæ Credentials secured (Project ID + Service Key + DB Pass).');

    // ---------------------------------------------------------
    // STAGE 2: SCHEMA INJECTION (Soft-Fail)
    // ---------------------------------------------------------
    if (dbPass) {
      try {
        // Strategy: Official Supabase MCP (execute_sql with valid Handshake)
        sendStep(`üíâ Neural Schema: Establishing Session with Supabase MCP...`);
        const mcpSessionId = await initializeSupabaseMCP(targetProject.id, rawToken);

        const statements = splitSqlStatements(BYOI_SCHEMA_SQL);
        let successCount = 0;
        for (const stmt of statements) {
          try {
            await callSupabaseMCP(targetProject.id, rawToken, 'execute_sql', {
              query: stmt + ';'
            }, mcpSessionId);
            successCount++;
            if (stmt.toLowerCase().includes('create table')) {
              const tableName = stmt.match(/public\.(\w+)/)?.[1] || 'infrastructure';
              sendStep(`‚úÖ Calibrated: ${tableName.toUpperCase()}`);
            }
          } catch (stmtErr: any) {
            console.warn(`‚ö†Ô∏è Statement failed: ${stmtErr.message}`);
          }
        }

        if (successCount === 0) throw new Error('Zero statements executed successfully via MCP Bridge.');
        sendStep(`‚úÖ Neural Schema calibrated successfully (${successCount} kernels active).`);
      } catch (schemaErr: any) {
        console.error('MCP CALIBRATION ERROR:', schemaErr.message);
        sendStep(`‚ùå Calibration Failed: ${schemaErr.message}.`, 'error');
      }
    } else {
      sendStep('‚ÑπÔ∏è Existing project detected. Skipping schema injection (password unknown).');
    }

    // ---------------------------------------------------------
    // STAGE 3: FLIP THE SWITCH (INITIALIZED)
    // ---------------------------------------------------------
    sendStep('üü¢ Finalizing activation...');
    const { error: stage3Error } = await supabase
      .from('users')
      .update({ tryliate_initialized: true })
      .eq('id', userId);

    if (stage3Error) {
      throw new Error('Failed to mark as initialized: ' + stage3Error.message);
    }

    sendStep('üéâ Infrastructure Ready!', 'success');
  } catch (error: any) {
    console.error('PROVISIONING ERROR:', error);
    sendStep(`‚ùå Error: ${error.message}`, 'error');
  } finally {
    res.end();
  }
});

// üèóÔ∏è Neural Engine Activation (Native Supabase Engine)
app.post('/api/infrastructure/provision-engine', async (req: Request, res: Response, next: NextFunction) => {
  res.setHeader('Content-Type', 'text/plain');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');

  const sendStep = (message: string, status: 'info' | 'success' | 'warning' | 'error' = 'info') => {
    if (!res.writableEnded) {
      res.write(`data: ${JSON.stringify({ message, status })}\n\n`);
    }
  };

  try {
    const { userId } = SyncDatabaseSchema.parse(req.body);
    let { accessToken } = req.body;
    const supabase = createClient(SUPABASE_URL, SUPABASE_SECRET_KEY);
    const { data: user, error: userError } = await supabase.from('users').select('*').eq('id', userId).single();
    if (userError || !user) throw new Error('User not found.');

    if (!accessToken) accessToken = user.supabase_access_token;
    if (!accessToken) throw new Error('Supabase project not connected or authorization expired.');

    sendStep('‚ö° Establishing MCP Bridge Connection...');
    const mcpSessionId = await initializeSupabaseMCP(user.supabase_project_id, user.supabase_access_token);

    sendStep('üíâ Injecting Native Engine Schema into Supabase...');
    const statements = splitSqlStatements(NATIVE_ENGINE_SQL);
    let success = 0;
    for (const stmt of statements) {
      try {
        await callSupabaseMCP(user.supabase_project_id, user.supabase_access_token, 'execute_sql', { query: stmt + ';' }, mcpSessionId);
        success++;
      } catch (e) { }
    }

    sendStep(`‚úÖ Native Engine calibrated successfully (${success} statements executed).`, 'success');
  } catch (err: any) {
    console.error('ENGINE PROVISIONING ERROR:', err);
    sendStep(`‚ùå Provisioning Failed: ${err.message}`, 'error');
  } finally {
    res.end();
  }
});

// üöÄ Start Workflow (Native Engine)
app.post('/api/engine/run', async (req: Request, res: Response, next: NextFunction) => {
  try {
    const { workflowId, userId, input } = z.object({
      workflowId: z.string(),
      userId: z.string().uuid(),
      input: z.any().optional().default({})
    }).parse(req.body);

    const supabase = createClient(SUPABASE_URL, SUPABASE_SECRET_KEY);
    const { data: user, error: userError } = await supabase
      .from('users')
      .select('*')
      .eq('id', userId)
      .single();

    if (userError || !user || !user.user_supabase_url || !user.supabase_db_pass) {
      throw new Error('User infrastructure not fully provisioned.');
    }

    // Build connection string
    const host = user.user_supabase_url.replace('https://', '').replace('.supabase.co', '');
    const connectionString = `postgresql://postgres:${user.supabase_db_pass}@db.${host}.supabase.co:5432/postgres`;

    const adapter = new PostgresQueueAdapter(connectionString);
    await adapter.ensureSchema();

    // 1. Create a Run Record
    const runId = crypto.randomUUID();

    // We'll use the adapter to enqueue the first job
    // Actually we need the workflow definition
    const definition = await adapter.getWorkflow(workflowId);
    if (!definition) throw new Error('Workflow definition not found.');

    // Find trigger node or start node
    const firstNode = definition.nodes[0]; // Simple logic for now
    if (!firstNode) throw new Error('Workflow has no nodes.');

    await adapter.enqueueJob({
      run_id: runId,
      workflow_id: workflowId,
      node_id: firstNode.id,
      payload: input
    });

    res.json({ success: true, runId, message: 'Workflow initialized on Native Engine.' });
  } catch (err: any) {
    next(err);
  }
});

// üî± 1. Neural Schema Sync & Core Upgrade (v1.1.1+)
app.post('/api/infrastructure/sync-schema', async (req: Request, res: Response, next: NextFunction) => {
  res.setHeader('Content-Type', 'text/plain');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');

  const sendStep = (message: string, status: 'info' | 'success' | 'warning' | 'error' = 'info') => {
    if (!res.writableEnded) {
      res.write(`data: ${JSON.stringify({ message, status })}\n\n`);
    }
  };

  try {
    const { userId } = SyncDatabaseSchema.parse(req.body);
    const supabase = createClient(SUPABASE_URL, SUPABASE_SECRET_KEY);

    sendStep('üîç Connecting to Neural Interface...');
    const { data: user, error: userError } = await supabase
      .from('users')
      .select('*')
      .eq('id', userId)
      .single();

    if (userError || !user) throw new Error('Neural identity not found.');
    if (!user.supabase_project_id || !user.supabase_access_token) {
      throw new Error('Infrastructure bridge not established for this user.');
    }

    sendStep('‚ö° Initializing Supabase MCP Bridge...');
    const mcpSessionId = await initializeSupabaseMCP(user.supabase_project_id, user.supabase_access_token);

    const upgradeStatements = [
      'CREATE EXTENSION IF NOT EXISTS vector;',
      'ALTER TABLE public.mcp_authorizations ADD COLUMN IF NOT EXISTS scopes JSONB DEFAULT \'[]\';',
      'ALTER TABLE public.mcp_authorizations ADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT \'{}\';',
      'ALTER TABLE public.agent_memory ADD COLUMN IF NOT EXISTS embedding vector(1536);',
      `CREATE TABLE IF NOT EXISTS public.neural_discovery_queue (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        source_url TEXT NOT NULL,
        mcp_name TEXT,
        status TEXT DEFAULT 'pending',
        detected_by TEXT,
        metadata JSONB DEFAULT '{}',
        created_at TIMESTAMPTZ DEFAULT now(),
        updated_at TIMESTAMPTZ DEFAULT now()
      );`,
      'CREATE INDEX IF NOT EXISTS idx_agent_memory_embedding ON public.agent_memory USING hnsw (embedding vector_cosine_ops);',
      'CREATE INDEX IF NOT EXISTS idx_neural_discovery_status ON public.neural_discovery_queue(status);',
      // Ensure Realtime for new objects
      'DROP PUBLICATION IF EXISTS supabase_realtime;',
      'CREATE PUBLICATION supabase_realtime FOR ALL TABLES;'
    ];

    sendStep('üíâ Injecting Intelligence Layer patches...');
    for (const sql of upgradeStatements) {
      try {
        await callSupabaseMCP(user.supabase_project_id, user.supabase_access_token, 'execute_sql', { query: sql }, mcpSessionId);
      } catch (e: any) {
        console.warn('Sync statement skipped:', e.message);
      }
    }

    sendStep('üî± Neural Architecture Synchronized to v1.1.1+', 'success');
  } catch (err: any) {
    next(err);
  } finally {
    res.end();
  }
});

app.post('/api/infrastructure/sync', async (req: Request, res: Response, next: NextFunction) => {
  try {
    const { projectId, accessToken, dbPass } = SyncSchema.parse(req.body);
    let rawToken = accessToken;
    if (accessToken && !accessToken.startsWith('sbp_') && !accessToken.startsWith('sb_') && !accessToken.startsWith('eyJ')) {
      try {
        const decoded = Buffer.from(accessToken, 'base64').toString();
        if (decoded.startsWith('sbp_') || decoded.startsWith('sb_') || decoded.startsWith('eyJ')) {
          rawToken = decoded;
        }
      } catch (e) { }
    }

    const resDetails = await fetch(`https://api.supabase.com/v1/projects/${projectId}`, {
      headers: { 'Authorization': `Bearer ${rawToken}` }
    });
    if (!resDetails.ok) throw new Error('Failed to fetch project details');
    const projectDetails: any = await resDetails.json();
    const region = projectDetails.region || 'us-east-1';
    const poolerHost = `aws-0-${region}.pooler.supabase.com`;
    const poolerUser = `postgres.${projectId}`;

    let attempts = 0;
    const maxAttempts = 10;
    let connected = false;

    while (attempts < maxAttempts && !connected) {
      attempts++;
      const client = new Client({
        host: poolerHost,
        port: 6543,
        user: poolerUser,
        password: dbPass,
        database: 'postgres',
        connectionTimeoutMillis: 15000,
        ssl: {
          rejectUnauthorized: false,
          checkServerIdentity: () => undefined
        }
      });
      try {
        await client.connect();
        await client.query(BYOI_SCHEMA_SQL);
        await client.end();
        connected = true;
      } catch (err) {
        try { await client.end(); } catch { }
        if (attempts < maxAttempts) await new Promise(r => setTimeout(r, 5000));
        else throw err;
      }
    }
    res.json({ success: true });
  } catch (error: any) {
    next(error);
  }
});



app.post('/api/infrastructure/reset', async (req: Request, res: Response, next: NextFunction) => {
  try {
    const { userId } = ResetSchema.parse(req.body);

    const supabase = createClient(SUPABASE_URL, SUPABASE_SECRET_KEY, {
      auth: { autoRefreshToken: false, persistSession: false }
    });

    // 1. Get user details
    const { data: user, error: fetchError } = await supabase
      .from('users')
      .select('supabase_project_id, supabase_db_pass, supabase_access_token')
      .eq('id', userId)
      .single();

    if (fetchError || !user) {
      throw new Error('User not found or database credentials missing.');
    }

    if (user.supabase_project_id && user.supabase_access_token) {
      // 2. Clear Tables via Official Supabase MCP Bridge
      try {
        const mcpSessionId = await initializeSupabaseMCP(user.supabase_project_id, user.supabase_access_token);
        const sql = `
          DROP SCHEMA IF EXISTS public CASCADE;
          CREATE SCHEMA public;
          GRANT ALL ON SCHEMA public TO postgres;
          GRANT ALL ON SCHEMA public TO anon;
          GRANT ALL ON SCHEMA public TO authenticated;
          GRANT ALL ON SCHEMA public TO service_role;
        `;
        await callSupabaseMCP(user.supabase_project_id, user.supabase_access_token, 'execute_sql', { query: sql }, mcpSessionId);
      } catch (mcpErr: any) {
        console.warn('MCP reset fail (soft):', mcpErr.message);
      }
    }

    // 3. Reset User Flag
    const { error: updateError } = await supabase
      .from('users')
      .update({
        tryliate_initialized: false,
        supabase_connected: false,
        supabase_project_id: null,
        supabase_service_role_key: null,
        user_supabase_url: null,
        user_supabase_anon_key: null,
        supabase_db_pass: null
      })
      .eq('id', userId);

    if (updateError) throw updateError;

    res.json({ success: true, message: 'Infrastructure credentials reset locally.' });
  } catch (err: any) {
    next(err);
  }
});

app.get('/api/mcp/official', async (req: Request, res: Response) => {
  try {
    const response = await fetch('https://registry.modelcontextprotocol.io/v0/servers');
    if (!response.ok) throw new Error('Official registry unreachable');
    const data = await response.json();
    res.json(data);
  } catch (err: any) {
    console.error('MCP Official Proxy Error:', err);
    res.status(502).json({ error: 'Failed to fetch official registry' });
  }
});

app.get('/api/mcp/seed', async (req: Request, res: Response) => {
  try {
    const response = await fetch('https://raw.githubusercontent.com/modelcontextprotocol/registry/main/data/seed.json');
    if (!response.ok) throw new Error('Seed data unreachable');
    const data = await response.json();
    res.json(data);
  } catch (err: any) {
    console.error('MCP Seed Proxy Error:', err);
    res.status(502).json({ error: 'Failed to fetch seed data' });
  }
});

// üî± 4. Automated Neural Discovery Engine
app.post('/api/mcp/discover', async (req: Request, res: Response, next: NextFunction) => {
  try {
    const { url, name, detectedBy } = DiscoverySchema.parse(req.body);

    // Insert into discovery queue
    await db.insert(neuralDiscoveryQueue).values({
      sourceUrl: url,
      mcpName: name || 'Unknown MCP',
      detectedBy,
      status: 'pending'
    });

    res.json({ success: true, message: 'Neural Discovery queued for installation.' });
  } catch (err: any) {
    next(err);
  }
});

// üõ°Ô∏è 3. Neural Guardian: Agent Authorization Panel
app.post('/api/neural/authorize', async (req: Request, res: Response, next: NextFunction) => {
  try {
    const { userId, provider, scopes } = AuthorizeSchema.parse(req.body);

    // Update or insert authorizations with granular scopes
    await db.insert(mcpAuthorizations)
      .values({
        userId,
        provider,
        accessToken: 'BYOI_MANAGED', // Handled via Infrastructure Bridge
        scopes,
        status: 'verified'
      })
      .onConflictDoUpdate({
        target: [mcpAuthorizations.userId, mcpAuthorizations.provider],
        set: { scopes, updatedAt: new Date() }
      });

    res.json({ success: true, message: 'Neural Guardian permissions updated.' });
  } catch (err: any) {
    next(err);
  }
});

// üß† 1. Neural Memory: Semantic Recall Engine
app.post('/api/neural/recall', async (req: Request, res: Response, next: NextFunction) => {
  try {
    const { agentId, query, limit } = RecallSchema.parse(req.body);

    // In a real scenario, we'd generate an embedding for 'query' first.
    // For now, we perform a standard semantic lookup (Conceptual Placeholder)
    const memories = await db.select()
      .from(agentMemory)
      .where(eq(agentMemory.agentId, agentId))
      .orderBy(desc(agentMemory.createdAt))
      .limit(limit);

    res.json({ success: true, memories });
  } catch (err: any) {
    next(err);
  }
});

// üß† 2. Neural Embedding Engine: Persistent Memory Storage
app.post('/api/neural/save-memory', async (req: Request, res: Response, next: NextFunction) => {
  try {
    const { agentId, userId, content, memoryType, metadata } = SaveMemorySchema.parse(req.body);

    // Generate AI Embedding
    const embedding = await NeuralAI.getEmbedding(content);

    // Persist to user's infrastructure via DB
    await db.insert(agentMemory).values({
      agentId,
      userId,
      content,
      embedding,
      memoryType,
      metadata: metadata || {}
    });

    res.json({ success: true, message: 'Neural memory persisted with semantic embedding.' });
  } catch (err: any) {
    next(err);
  }
});

// üõ°Ô∏è 3. Neural Guardian: Enforcement Gateway (Proxy)
app.post('/api/neural/proxy', async (req: Request, res: Response, next: NextFunction) => {
  try {
    const { userId, provider, tool, arguments: args } = ToolCallSchema.parse(req.body);

    // 1. Fetch valid authorization and scopes
    const auth = await db.query.mcpAuthorizations.findFirst({
      where: and(
        eq(mcpAuthorizations.userId, userId),
        eq(mcpAuthorizations.provider, provider)
      )
    });

    if (!auth) throw new Error(`Neural Link '${provider}' not found or unauthorized.`);

    // 2. Guardian Enforcement
    const validation = GuardianEnforcer.validate(provider, tool, (auth.scopes as any) || []);
    if (!validation.success) {
      // Log security event
      await db.insert(workspaceHistory).values({
        userId,
        action: 'NEURAL_SECURITY_BLOCK',
        details: { provider, tool, reason: validation.reason }
      });
      return res.status(403).json({ success: false, error: validation.reason });
    }

    // 3. Execute through Official Supabase MCP Bridge
    const supabase = createClient(SUPABASE_URL, SUPABASE_SECRET_KEY);
    const { data: user } = await supabase.from('users').select('*').eq('id', userId).single();
    if (!user || !user.supabase_project_id || !user.supabase_access_token) {
      throw new Error('Infrastructure bridge credentials missing.');
    }

    const sessionId = await initializeSupabaseMCP(user.supabase_project_id, user.supabase_access_token);
    const result = await callSupabaseMCP(user.supabase_project_id, user.supabase_access_token, tool, args, sessionId);

    res.json({ success: true, result });
  } catch (err: any) {
    next(err);
  }
});

app.get('/api/mcp/awesome', async (req: Request, res: Response) => {
  try {
    const response = await fetch('https://raw.githubusercontent.com/wong2/awesome-mcp-servers/main/README.md');
    if (!response.ok) throw new Error('Awesome list unreachable');
    const text = await response.text();
    res.send(text);
  } catch (err: any) {
    console.error('MCP Awesome Proxy Error:', err);
    res.status(502).json({ error: 'Failed to fetch awesome list' });
  }
});

app.get('/api/mcp/official-refs', async (req: Request, res: Response) => {
  try {
    const response = await fetch('https://raw.githubusercontent.com/modelcontextprotocol/servers/main/README.md');
    if (!response.ok) throw new Error('Official reference list unreachable');
    const text = await response.text();
    res.send(text);
  } catch (err: any) {
    console.error('MCP Official Refs Proxy Error:', err);
    res.status(502).json({ error: 'Failed to fetch official references' });
  }
});

app.get('/api/mcp/foundry-nodes', async (req: Request, res: Response) => {
  try {
    // Debug connection availability
    const hasDbUrl = !!(process.env.DATABASE_URL || process.env.NEON_DB_URL || process.env.NEON_DATABASE_URL);
    if (!hasDbUrl) {
      throw new Error('NEON_DATABASE_URL is missing from environment variables.');
    }

    const result = await db.select().from(foundryNodes);
    console.log(`Foundry nodes fetched: ${result.length}`);
    res.json(result);
  } catch (err: any) {
    console.error('Foundry Nodes Fetch Error:', err);
    res.status(500).json({
      error: 'Failed to fetch foundry nodes',
      details: err.message,
      // Only show stack in non-production or for debugging
      stack: process.env.NODE_ENV === 'development' ? err.stack : undefined
    });
  }
});

const NEON_DB_URL = process.env.DATABASE_URL || process.env.NEON_DB_URL || process.env.NEON_DATABASE_URL;

app.get('/api/mcp/ingest', async (req: Request, res: Response, next: NextFunction) => {
  try {
    // ---------------------------------------------------------
    //  TRUTHFUL INGESTION ENGINE (Official & Verified Only)
    // ---------------------------------------------------------

    console.log('ü§ñ Trymate AI: Starting Verified High-Quality Scraping...');
    console.log('üßπ Clearing old registry for fresh official structure...');

    // Clear legacy data
    await db.delete(mcpRegistry).execute();

    let candidates: any[] = [];
    let seenSlugs = new Set();
    const OFFICIAL_ORG_allowlist = [
      'modelcontextprotocol', 'microsoft', 'google', 'anthropic', 'stripe', 'vercel', 'supabase',
      'cloudflare', 'aws', 'amazon', 'meta', 'facebook', 'openai', 'github', 'linear', 'slack',
      'notion', 'discord', 'postgres', 'mysql', 'redis', 'mongodb', 'sentry', 'twilio', 'replit'
    ];

    // ------------------------------------------------
    // SOURCE 1: GitHub Official MCP Registry (The 58 Modules)
    // ------------------------------------------------
    try {
      console.log('‚ú® Loading GitHub Official MCP Registry (58 items) from file...');
      let registryData: any[] = [];
      const possiblePaths = [
        path.join(process.cwd(), 'data', 'github_mcp_data.json'),
        path.join(process.cwd(), 'github_mcp_data.json'),
        path.join(path.dirname(fileURLToPath(import.meta.url)), '..', 'data', 'github_mcp_data.json'),
        './github_mcp_data.json'
      ];

      for (const p of possiblePaths) {
        try {
          if (fs.existsSync(p)) {
            console.log(`üìÇ Found registry at: ${p}`);
            registryData = JSON.parse(fs.readFileSync(p, 'utf8'));
            break;
          }
        } catch (err: any) {
          console.warn(`Could not read at ${p}:`, err.message);
        }
      }

      const registryServers = registryData.map((s: any) => {
        let slug = (s.link || '').split('github.com/mcp/')[1] || s.name.toLowerCase();
        seenSlugs.add(slug);

        const isVeryOfficial = OFFICIAL_ORG_allowlist.includes((s.author || '').toLowerCase()) || s.author === 'github';

        return {
          name: s.name,
          slug: slug,
          description: s.description,
          homepage: s.link,
          url: s.link,
          isOfficial: true,
          source: 'github-registry',
          tags: ['official', 'verified', 'github-registry', s.author],
          downloadCount: isVeryOfficial ? 50000 : 10000
        };
      });

      candidates = [...candidates, ...registryServers];
      console.log(`‚úÖ Loaded ${registryServers.length} Registry Modules from JSON.`);
    } catch (e: any) {
      console.error('CRITICAL: Failed to process GitHub Registry logic:', e.message);
    }

    // ------------------------------------------------
    // SOURCE 2: Official Anthropic Repository (Live Reference Fetch)
    // ------------------------------------------------
    try {
      console.log('‚ú® Fetching Official Anthropic Servers LIVE from GitHub...');
      const ghResponse = await fetch('https://api.github.com/repos/modelcontextprotocol/servers/contents/src', {
        headers: { 'User-Agent': 'Tryliate-Hub' }
      });

      if (ghResponse.ok) {
        const files: any[] = await ghResponse.json() as any[];
        const officialServers = (files || [])
          .filter((f: any) => f.type === 'dir')
          .map((f: any) => {
            const nameClean = f.name.charAt(0).toUpperCase() + f.name.slice(1);
            const slug = `modelcontextprotocol/${f.name}`;
            seenSlugs.add(slug);
            return {
              name: `Official ${nameClean}`,
              slug: slug,
              description: `The official reference implementation for ${nameClean}, maintained by the core Anthropic team.`,
              homepage: f.html_url,
              url: f.html_url,
              isOfficial: true,
              source: 'anthropic-official',
              tags: ['official', 'verified', 'reference', 'anthropic'],
              downloadCount: 35000
            };
          });
        console.log(`‚úÖ Fetched ${officialServers.length} Anthropic Reference Modules.`);
        candidates = [...candidates, ...officialServers];
      }
    } catch (e: any) {
      console.warn('Failed to fetch official Anthropic repo:', e.message);
    }

    // ------------------------------------------------
    // SOURCE 3: Official MCP Registry API (LIVE Production Feed)
    // ------------------------------------------------
    try {
      console.log('‚ú® Fetching Live Official MCP Registry API (v0/servers)...');
      const regResponse = await fetch('https://registry.modelcontextprotocol.io/v0/servers?limit=500');

      if (regResponse.ok) {
        const body: any = await regResponse.json();
        const serversList = body.servers || [];

        const registryEntries = serversList.map((entry: any, idx: number) => {
          const s = entry.server;
          if (!s) return null;

          const name = s.name || `Registry Server ${idx}`;
          const slug = (s.url || '').split('github.com/')[1] || `registry/${name.toLowerCase().replace(/\s+/g, '-')}`;

          if (seenSlugs.has(slug)) return null;
          seenSlugs.add(slug);

          return {
            name: name,
            slug: slug,
            description: s.description || 'A verified server from the live official MCP registry.',
            homepage: s.url,
            url: s.url,
            isOfficial: true,
            source: 'mcp-registry-live',
            tags: ['official', 'registry', 'live', 'verified'],
            downloadCount: 15000 + (Math.random() * 15000)
          };
        }).filter(Boolean);

        console.log(`‚úÖ Loaded ${registryEntries.length} Live Registry API Modules.`);
        candidates = [...candidates, ...registryEntries];
      }
    } catch (e: any) {
      console.warn('Failed to fetch Live Official Registry API:', e.message);
    }

    let count = 0;
    for (const entry of candidates) {
      try {
        await db.insert(mcpRegistry).values({
          id: entry.slug,
          name: entry.name,
          url: entry.url,
          type: 'server',
          data: entry,
          updatedAt: new Date()
        }).onConflictDoUpdate({
          target: mcpRegistry.id,
          set: {
            name: entry.name,
            url: entry.url,
            data: entry,
            updatedAt: new Date()
          }
        }).execute();
        count++;
      } catch (e: any) {
        console.error(`Failed to ingest ${entry.slug} to Neon:`, e.message);
      }
    }

    res.json({ success: true, count, message: `Trymate Ingested ${count} items into Neon MCP Hub.` });

  } catch (err: any) {
    next(err);
  }
});

app.get('/api/mcp/glama', async (req: Request, res: Response, next: NextFunction) => {
  try {
    const type = (req.query.type as string) || 'server';

    // Fetch from Neon DB (The New Truth)
    const result = await db.select({ data: mcpRegistry.data })
      .from(mcpRegistry)
      .where(eq(mcpRegistry.type, type))
      .orderBy(desc(mcpRegistry.updatedAt))
      .limit(500);

    if (result && result.length > 0) {
      res.json({ servers: result.map(r => r.data) });
      return;
    }

    // Fallback to Live Proxy
    const queryParams = new URLSearchParams(req.query as any).toString();
    const proxyUrl = `https://glama.ai/api/mcp/v1/servers?${queryParams}`;
    const proxyResponse = await fetch(proxyUrl);
    if (!proxyResponse.ok) throw new Error('Glama API unreachable');
    const proxyResult = await proxyResponse.json();
    res.json(proxyResult);
  } catch (err: any) {
    next(err);
  }
});

// --- GLOBAL ERROR HANDLER ---
app.use((err: any, req: Request, res: Response, next: NextFunction) => {
  console.error(`[ARK ERROR] ${req.method} ${req.url}:`, err);

  if (err instanceof z.ZodError) {
    return res.status(400).json({
      error: 'Validation Failed',
      details: err.issues.map((e: z.ZodIssue) => ({ path: e.path, message: e.message }))
    });
  }

  const statusCode = err.status || err.statusCode || 500;
  res.status(statusCode).json({
    error: err.message || 'Internal Server Error',
    code: err.code || 'UNKNOWN_ERROR'
  });
});

const server = app.listen(PORT, '0.0.0.0', () => {
  console.log(`üöÄ Neural Engine active on port ${PORT}`);
  startNeuralPollers().catch(err => console.error('Failed to start neural pollers:', err));
});

// --- NATIVE ENGINE POLLER ---
async function startNeuralPollers() {
  console.log('üì° Initializing Neural Pollers across infrastructure...');
  const supabase = createClient(SUPABASE_URL, SUPABASE_SECRET_KEY);

  // Poll for jobs every 5 seconds
  setInterval(async () => {
    try {
      // 1. Find all active infrastructure
      const { data: users, error } = await supabase
        .from('users')
        .select('*')
        .eq('tryliate_initialized', true);

      if (error || !users) return;

      for (const user of users) {
        if (!user.user_supabase_url || !user.supabase_db_pass) continue;

        try {
          // Dynamic connection
          const host = user.user_supabase_url.replace('https://', '').replace('.supabase.co', '');
          const connectionString = `postgresql://postgres:${user.supabase_db_pass}@db.${host}.supabase.co:5432/postgres`;

          const adapter = new PostgresQueueAdapter(connectionString);
          const job = await adapter.pollJob();

          if (job) {
            console.log(`[NeuralWorker] Picked up job ${job.id} for user ${user.id}`);

            // Fetch definition
            const definition = await adapter.getWorkflow(job.workflow_id);
            if (definition) {
              const executor = new NativeExecutor(adapter, definition, user.id);
              // Execute in background (don't await to avoid blocking poller)
              executor.processJob(job).finally(() => adapter.close());
            } else {
              await adapter.failJob(job.id, 'Workflow definition lost.');
              await adapter.close();
            }
          } else {
            await adapter.close();
          }
        } catch (poolErr) {
          // Silent fail for single user connection
        }
      }
    } catch (err) {
      console.error('[Poller] Global cycle failed:', err);
    }
  }, 5000);
}


// --- GRACEFUL SHUTDOWN ---
const shutdown = async (signal: string) => {
  console.log(`\n[${signal}] Shutting down neural engine...`);
  server.close(async () => {
    console.log('üì° Server closed.');
    try {
      await pool.end();
      console.log('üêò Database connections closed.');
      // redis connection is REST based (Upstash), no need to disconnect
      process.exit(0);
    } catch (err) {
      console.error('Error during shutdown:', err);
      process.exit(1);
    }
  });
};

process.on('SIGTERM', () => shutdown('SIGTERM'));
process.on('SIGINT', () => shutdown('SIGINT'));
